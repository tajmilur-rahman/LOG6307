\documentclass[10pt, conference]{IEEEtran}
\usepackage[english]{babel}
\usepackage[usenames]{color}
\usepackage{colortbl}
\usepackage{comment}
\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{array, colortbl}
\usepackage{listings}
\usepackage{epstopdf}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{caption}
%\usepackage{subfigure}
\usepackage{subfig}
\usepackage{float}
\usepackage[obeyspaces,hyphens,spaces]{url}
\usepackage{balance}
\usepackage{fancybox}
\usepackage{scalefnt}
\usepackage[normalem]{ulem}
%\pagestyle{plain}
\pagenumbering{arabic}
\pagestyle{empty}
\clubpenalty = 10000
\widowpenalty = 10000
\displaywidowpenalty = 10000
\usepackage{cleveref}

\makeatletter
\renewcommand{\paragraph}[1]{\noindent\textsf{#1}.}

\title{An Empirical Study for Prioritizing Quality Assurance : A Replication Work}
\author{Md Tajmilur Rahman$^{1}$, Louis-Philippe Querel$^{1}$
    \\
	\emph{$^{1}$ Dept. of Computer Science and Engineering, Concordia University, Qu\'{e}bec, Canada}
}

\begin{document}
\maketitle

\begin{abstract}
Quality Assurance by predicting defects in software systems is a highly studied area in the current trend of software engineering research. Predicting defect prone files or modules are still not sufficient to save time to identify actual defects inside the code that needs to be modified to fix a bug. In this case predicting actual defect-inducing change could be a better approach to resolve this insufficiency and may reduce the effort of fixing defects. One research work had already been done which focused on the issue of predicting defect-inducing changes in change/churn level. This influenced us to replicate the work on the small scale open source project Django. We correlate actual bug fixing changes with commits to improve quality of the dataset. A zero-R model has been implied to validate our logistic regression model. The result of our replication on Django project is different than the original work and we found that the defect-inducing factors from the original work have a defect-reducing characteristic in our replication with Django.

\end{abstract}

\section{Introduction}
\label{sec:introduction}

Quality assurance in software development plays the prominent role for a software to turn it into a successful business product. Doing business with a software product by providing services or by selling the software itself demands high level of quality assurance and quality can be assured in software industries by unit test, black-box, white-box, integration, functional and system level testing. Testing is not just the end of the quality assurance but the start of working for assuring quality of a software system. Testing produces list of regressions and flaws throughout the system that keeps the development team busy for fixing bugs to make the system flaw-less. Generally this fixing and testing be practised during the stabilization period once all the new feature development works are done. We can estimate development time and cost prior to a development cycle but the effort that stabilization period consumes for fixing does influence the cost of software product and reputation of the software industry.

In current trend many researchers are focusing on predicting defects in the code-base of the software system~\cite{Gyimothy2005IEEE}. In some contexts this approach can be useful but they have drawbacks. Predicting bugs does not specify the amount of work and cannot minimize the effort in a great deal but comparatively predicting the particular change that could be defect inducing would be more efficient to reduce the effort for fixing bugs around the time of release. This is really important for reducing the stabilization time and releasing the software product sooner to beat competitors in the market.

As most of the quality assurance research works are based on defect prediction on change level we would like to predict defect inducing changes~\cite{Kim2008TSE}. We would like to illustrate the prediction of defect inducing change to enhance software quality by replicating the approach proposed by Kamei et al.~\cite{Kamei2013TSE}. We would like to do this work on a relatively small project DJango based on the following two main research questions:

\textit{RQ1, Prediction:} How well can we predict defect-inducing changes?

Kamei and his co-researchers used six open source projects and five commercial projects. We would like to see how well the model predicts defect-inducing changes in a different software project.

\textit{RQ2, Major Characteristics:} What are the major characteristics of defect-inducing changes?

To answer this research question we want to observe the factors having the largest impact on the predictions. We want to identify the major characteristics of the defect inducing changes and would like to see if the number of files and whether or not the change fixes a defect are risk-increasing factors, also if the average time interval since the previous change is a risk-decreasing factor in RQ1.

\section{Background and Related Work}
\label{sec:backgr-relat-work}

Due to achieve the quality assurance of a software system software engineers and researchers are concerned since many years. Many approaches have been followed and scientists have tried from many different angle to predict defects in software for enhancing quality assurance. Earlier in 2005 Nagappan and T. Ball did an interesting research in Microsoft to predict file level defect density~\cite{Nagappan2005ICSE} based on relative code-churn measure. Later on an approach of predicting defect-prone components has been studied by Nagappan et al. In this study they showed that the change bursts can predict defect-prone components in significantly high rate in comparison to other measures like code-churn or organization structure.

Many other researchers have used change measure, for example Mockus and Weiss~\cite{Mockus2000Bell} used change measures, such as the number of subsystems those are changed, number of modified, lines of code added and the number of modification requests. Now a days churn factor measure become a very traditional approach in predicting defects. From a slightly different angle Sunghun Kim~\cite{Kim2011ICSE} proposes an approach to deal with the noise in defect data as he could realize that automatically collected defect data based on the change logs could include noises.

\begin{table*}[t]
	\centering
	\caption{Summary of Change Measures}
	\begin{tabular}{|c|l|p{2.5cm}|p{5.5cm}|p{5.25cm}|}
		\hline Dim. & Name & Definition & Rationale & Related Work \\ 
		\hline \multirow{14}{*}{\begin{sideways}Diffusion\end{sideways}} & NS & Number of modified subsystems  & Changes modifying many subsystems are more likely to be defect-prone. & The defect probability of a change increases with the number of modified subsystems \cite{Mockus2000Bell}. \\ \cline{2-5}  
		& ND & Number of modified directories & Changes touching many files are more likely to be defect-prone. & The higher the number of modified directories, the higher the chance that a change will induce a defect \cite{Mockus2000Bell}. \\ \cline{2-5}  
		& NF & Number of modified files & Changes touching many files are more likely to be defect-prone. & The number of classes in a module is a good featureof post-release defects of a module \cite{Nagappan2006ICSE}. \\ \cline{2-5} 
		& Entropy & Distribution of modified code across each file & Changes with high entropy are more likely to be defect-prone, because a developer will have to recall and track large numbers of scattered changes across each file. & Scattered changes are more likely to introduce defects \cite{DAmbross2010MSR, Hassan2009ICSE}. \\ 
		\hline \multirow{4}{*}{\begin{sideways}Size\end{sideways}} & LA & Lines of code added & The more lines of code added, the more likely a defect is introduced. & \multirow{2}{5.25cm}{Relative code churn measures are good indicators of defect modules \cite{Moser2008ICSE, Nagappan2005ICSE}}. \\ \cline{2-4} 
		& LD & Lines of code deleted & The more lines of code deleted, the higher the chance of a defect. &  \\ 
		\hline \multirow{4}{*}{\begin{sideways}Purpose\end{sideways}} & FIX & Whether or not the change is defect fix & Fixing a defect means that an error was made in an earlier implementation, therefore it may indicate an area where errors are more likely. & Changes that fix defects are more likely to introduce defects than changes that implement new functionality \cite{Guo2010ICSE, Purushothaman2005IEEE}. \\ 
		\hline \multirow{13}{*}{\begin{sideways}History\end{sideways}} & NDEV & The number of developers that changed the modified files & The larger the NDEV, the more likely a defect is introduced, because files revised by many developers often contain different design thoughts and coding styles. & Files previously touched by more developers contain more defects \cite{Matsumoto2010PROMISE}. \\ \cline{2-5} 
		& AGE & The avergae time interval between the last and current change & The lower the AGE (i.e., the more recent the last change), the more likely a defect will be introduced. & More recent changes contribute more defects than older changes \cite{Graves2000IEEE}. \\ \cline{2-5} 
		& NUC & The number of unique changes to the modified files & The larger the NUC, the more likely a defect is introduced, because a developer will have to recalland track many previous changes. & The larger the spread of modified files, the higher the complexity \cite{DAmbross2010MSR, Hassan2009ICSE}. \\ 
		\hline \multirow{10}{*}{\begin{sideways}Experience\end{sideways}} & EXP & Developer experience & More experienced developers are less likely to introduced a defect. & Programmer experience significantly decreases the defect probability \cite{Mockus2000Bell}. \\ \cline{2-4} 
		& REXP & Recent developer experience & A developer that has often modified the files in recent months is less likely to introduce defect, because they will be more familiar with recent developments in the system. &  \\ \cline{2-4} 
		& SEXP & Developer experience on a subsystem & Developers that are familiar with the subsystems modified by a change are less likely to introduce defects. &  \\ 
		\hline 
	\end{tabular} 
	\label{table:factors}
\end{table*}

Many research have been performed comparing open source and commercial projects. Briand et al.~\cite{Briand1999ICSE} did an analysis with the relationship between software design and quality. Zimmermann et al.\cite{Zimmermann2009ESECS} showed that there is no single factor that leads to accurate predictions. They focused on defect prediction from one project to another based on seven commercial projects and four open source projects. Existing research works create the impression that we can predict defects in a software system in many different ways having little variation in accuracy and prediction performance. But this does not help us reducing the fixing time that much. We still need to find out the particular change in the code that is involved in producing the bug.

Previous works are mostly just predicting defects, many of them are also focusing on quality assurance by predicting the probability of defects or the number of defects for a particular location in the system back-end. In contrast to many of these studies Kamei et al.~\cite{Kamei2013TSE} focus on predicting the probability of a software change inducing a defect at check-in time. Actually this research of Kamei et al. made us interested and in this paper we are basically replicating this work o Kamei and his co-workers.

\section{Approach}
\label{sec:approach}



Similarly to Kamei's work, we use a logistic regression model to perform our prediction~\cite{Kamei2013TSE}. We are collecting the historical data of Django from it's git repository and the tables that we generate to store the historical data contains commit information. A commit represents one change here. If a commit contains multiple files then we would like to say these files have got a change at this particular commit. For the SSZ algorithm which we use we also require the data for Django's defect tracker. Django uses the Trac ticket software system to keep track of tickets which are created for the project. We extracted these tickets of which 54\% of them have a type assigned to them which identify the category of work which it covers. These types can refer to bugs/defects, new features, enhancements and cleanup/optimization ticket tasks. Of these 54\% some of these tickets have their types as uncategorised  

We then used an hybrid of the SZZ and ASZZ algorithms\cite{Sliwerski2005MSR} which is used to link defect fix commit to the original commit which introduced the defect. This is a three step process which uses the acquired data. In the first step of the SZZ algorithm we attempt to identify the commits which were used to fix a defect. This is done by searching for ticket numbers in the commit's message and for keywords such as "bug", "defect", "fix" and "patch" \cite{Kamei2013TSE}. 

\begin{table*}[t]
	\caption{Django Project Statictics}
	\begin{tabular}{|p{2 cm}|p{1.5 cm}|p{1.5 cm}|p{1.5 cm}|p{1.5 cm}|p{1.5 cm}|p{1.5 cm}|p{1.5 cm}|p{1.5 cm}|}
		\hline 
		Period  & Total number of commits with changes  & Percentage of defect inducing commits  & Average LOC per file  & Avg. LOC per changes  & \# of modified files per changes  & \# of changes per day  & Max \# dev. per file  & Avg. \# of dev. per file \tabularnewline
		\hline 
		12/07/2005 - 19/09/2014  & 26606  & 28.2\% & 142.5 & 272.3 & 4.6 & 7.9 & 143 & 5.7 \\ \hline 
	\end{tabular}
	\label{table:statistics}	
\end{table*}

The second step involves the use of the defect tracking data to determine whether a commit which was identified in the first step can be linked to a tracked ticket and whether that ticket is a defect. Given that not all tickets are defects, the identifier of a ticket is not enough to say that a commit was used to fix a defect. This is why the link must be done and the ticket must be validated. However, the reason for our use of an hybrid of SZZ and ASZZ is the lack of information present in the issue tracker. We were able to link 60.0\% of the commits to tickets, but for 43.8\% of those commits it is not possible to determine what kind of ticket they are given that they have not been categorized. As a result we can only be certain of the category of 33.7\% of the commits. Due to this we have to augment our data using the ASZZ. In the event where we are unable to make a link or that the link doesn't have a type we use the keywords such as "bug", "defect", "fix" and "patch" \cite{Kamei2013TSE} to determine if the commit might have been fixing a defect. As a result we are able to determine that 34.1\% of commits were performed to fix a defect. 

Following the second step we shall now have a dataset where we know whether a commit served to fix a defect. Going into the third step we now want to determine from which commits these defects originated from. This is achieved using Git's ability to know from which commit a line originates from. Where we know that a commit replaced lines which contained a defect we can compare the fix commit to the previous commit to be able to blame those replaced lines. As a result we are able to determine the origin of the lines which were replaced. This however can result in false positives as other tasks such as refactoring might have been performed as part of the commit, but we do not have a way to discriminate against those. Following the execution we were able to determine that 28.2\% of commits were defect-inducing. 

From our data we also generated the change measurement factors as defined in the original paper. Table~\ref{table:factors} is a copy of factors table provided in the original paper \cite{Kamei2013TSE}. We then generated a logistic regression model based on these factors which were generated from our Django dataset. For each commit, the logistic regression model outputs a probability represented by a value ranging from 0 to 1. Like Kamei we also set a threshold value of 0.5 to make our prediction easier like: defect-inducing "yes" or "no"~\cite{Gyimothy2005TSE,Guo2010ICSE}.

Kamei et al. selected a minimal set of factors to include as independent variables to avoid over-fitting the models. We followed a similar approach at this point as we are also removing highly correlated factors manually but then instead of using Stepwise variable selection we are using the CfsSubsetEval evaluator~\cite{Hall1998} to remove the remaining collinear metrics and those metrics that do not contribute to the model. We used accuracy, precision, recall, and F1-measures to evaluate the performance of our model. The confusion matrix has been represented in Table~\ref{table:confusion}. A change True Positive (TP) indicates that the corresponding change is Defect inducing and False Negative (FN) indicates that the change is non-defect-inducing.



\section{Results}
\label{sec:results}

In this section we will be presenting the results of our research questions which replicated the original paper. Django, the project which was selected for this replication is of similar size to other open source projects in the original paper (Table~\ref{table:statistics}). While Bugzilla is also a web application, it is programmed in a different programming language. As such Django which is a web development framework written in python will serve to comparision to other open source projects which we being used in the original paper.

\begin{table}[t]
	\centering
	\caption{Django Confusion Matrix}
	\begin{tabular}{|c|c|c|}
		\hline 
		true /\ classified  & No defect  & defect \tabularnewline
		\hline 
		No defect  & 19121  & 832 \tabularnewline
		\hline 
		defect  & 6413  & 1096 \tabularnewline
		\hline 
	\end{tabular}
	\label{table:confusion}
\end{table}

\subsection{RQ1: How well can we predict defect-inducing changes?}
\label{sec:rq1}

Using our model we want to determine how well we can predict defect-indusing changes. This is achieved by building a model which uses the factors from the original paper using the Django dataset. Using logistic regression we can determine how these factors will have an impact on the probability that a change induces a defect, however some of these factor may correlate together and cause overfitting which may reduce the quality of our model.  

To avoid the overfitting of factors within the model we need to remove factors which are highly correlated. We used Weka's CfsSubsetEval~\cite{Hall1998} attribute evaluator using the exhaustive search approach to identify the factors to retain. Like with subsequent models we used a 10 fold cross-validation approach to reduce the error rate of our model that could result from the data. Following it's execution it was determined that the factors NS, Entropy, LA, NUC and REXP would have the least correlation. We therefore deleted other factors from our model and retained these factors which were specified.

Using this reduced model we then proceeded to run a 10 fold cross-validation of the logistic regression of the model. We present the results of the model in Tables \ref{table:confusion} and \ref{table:prediction}. The confusion matrix in table \ref{table:confusion} illustrate the performance of the model which used logistic regression and compares their results to the known values of which change introduced a defect. As illustrated we can see that our model performs better at identifying changes which cahnges are not defect-inducing. On changes which had no defects there was a recall of 95.8\% which reduce the risk of having a false positive. Of the 28.2\% (Table \ref{table:statistics}) of changes which are identified as defect-inducing in our dataset, only 14.6\% of these are recalled by the model. While there would be more instances of false negative, this would result in an increase in the number of defect-inducing changes which might go unnoticied until a defect ticket is openned by a user of the application. 


We used a ZeroR model with 10 folds cross-validation as our baseline to compare against our logistic regression model. Following the execution of both models we have their comparisation in table \ref{table:prediction}. Overall there is a 32.6\% precision increase in the logistic regression model compared to the baseline. This improvement indicate that our model performs better then the baseline and this is also confirmed with the improved area under the curve (AUC) of 38.0\%.  

\begin{table}
	\centering
	\caption{Prediction Performance}
	\begin{tabular}{|c|c|c|c|c||c|c|}
		\hline \multirow{2}{*}{Accuracy} & \multirow{2}{*}{Prec.} & \multirow{2}{*}{Recall} & \multirow{2}{*}{F1} & \multirow{2}{*}{AUC} & \multicolumn{2}{|c|}{\% improvement} \\ \cline{6-7} 
		 &  &  &  &  & Prec. & AUC \\  
		\hline 73.6\% & 70.0\% & 73.6\% & 67.4\% & 69.0\% & 32.6\% & 38.0\% \\ 
		\hline 
	\end{tabular}
	
	\label{table:prediction} 
\end{table}


\subsection{RQ2: What are the major characteristics of defect-inducing changes?}
\label{sec:rq2}

Using all the factors from our Django model (Table \ref{table:factors}) we can determine which factors are defect-inducing. Compared to the original paper this replication study only covers one open source project. Due to this we will be comparing it to the results of the original paper. 

We followed the approach presented in the original paper of using positive and negative signs to illustrate the effect which a factor as of inducing defects in a change. Factors with a positive sign (+) will result in a higher probability that a change is defect-inducing. On the other hand factors with a negative sign (-) have the opposite effect and reduce the probability that a change is defect inducing.  

Using the odds ratio results obtained from the model which are presented in table \ref{table:odds_ratio} we can determine the effect which these factors have on the probability that it is defect-inducing.  We can see that most factors have a negligable effect when the Django data is modelled. The number of directories in a change (ND) is the biggest defect-inducing factor for Django. Where a change includes modifications to more directories it shall be expected that there will be a higher probability of this change introducing a defect. More of the factors can be said to have a negative effect in inducing defects in Django. The number of subsystem (NS), Entropy and Fix fit within this category for Django. These results would indicate that the more subsystems are modified, the greater the risk of introducing a defect is reduced. The presence of Entropy as a defect-reducing factor would illustrate that the greater the distribution of changes in a Django change the lower the probability that a defet will be introduced. And finally where a change is made to correct an existing defect there is subsequent reduced probability of a defect being present in the lines affected by the change. 

The result of these three factors with a negative effect present a rejection of their rationales as defined in Table \ref{table:factors}. The rationales in Table \ref{table:factors} indicate the expected behaviors of the factors on the probability of inducing-defects, however the project is not required to follow these assumptions as these results illustrate. The results can also be briefly compared to that of the original paper. A more throurough comparision is performed later in section \ref{sec:comparison-results}.  The presence of NS and Fix as defect-reducing factors in the Django data appear to contradict the results which were presented in the original paper.

\begin{table}
	\centering
	\caption{The Impact of Change Factors on Defect-Inducing Changes}
	\begin{tabular}{|c|c|c|c|}
		\hline Metrics name & Impact & Django \\ 
		\hline NS & - & 0.6779 \\ 
		\hline ND & + & 1.0129 \\ 
		\hline NF &  & 1.0007 \\ 
		\hline Entropy & - & 0.6078 \\ 
		\hline LA &  & 1 \\ 
		\hline LD &  & 1 \\ 
		\hline FIX & - & 0.9536 \\ 
		\hline NDEV &  & 0.997 \\ 
		\hline AGE &  & 1.0003 \\ 
		\hline NUC &  & 0.965 \\ 
		\hline EXP &  & 1.0001 \\ 
		\hline REXP &  & 1 \\ 
		\hline SEXP &  & 0.9998 \\ 
		\hline 
	\end{tabular}
	\label{table:odds_ratio}  
\end{table}

The change factor's regression coefficients which are present in Table \ref{table:regression_coefficients} also illustrate similar results to the odds ratios of Table \ref{table:odds_ratio}. The finding which ND is defect-inducing in changes for Django is consistent with the results of the odds ratio in table \ref{table:odds_ratio}. A consistent selection of defect-reducing factors are also present in the regression coefficients in comparision to the odds ratio. The factors NS, Entropy, Fix and NUC would all reduce the probability of a change inducing defects in Django. The defect-reducing effect of NUC would indicate that the more changes which have been applied to a file the less probable it is that this file contains a defect. The defect-reducing effects of NS, Entropy and Fix were presented in a earlier paragraph of this section.
\begin{table}
	\centering
	\caption{The Regression Coefficients of Change Factors}
	\begin{tabular}{|c|c|c|c|}
		\hline Metrics name & Impact & Django \\ 
		\hline NS & - & -0.3887 \\ 
		\hline ND & + & 0.0128 \\ 
		\hline NF &  & 0.0007 \\ 
		\hline Entropy & - & -0.4978 \\ 
		\hline LA &  & 0 \\ 
		\hline LD &  & 0 \\ 
		\hline FIX & - & -0.0475 \\ 
		\hline NDEV &  & -0.003 \\ 
		\hline AGE &  & 0.0003 \\ 
		\hline NUC & - & -0.0356 \\ 
		\hline EXP &  & 0.0001 \\ 
		\hline REXP &  & 0 \\ 
		\hline SEXP &  & -0.0002 \\ 
		\hline 
	\end{tabular}
	\label{table:regression_coefficients}
\end{table}


\section{Comparison of Results}
\label{sec:comparison-results}

In comparison to the original work we would like to compare our RQ1 with RQ1 of the original paper and our RQ2 with the RQ3 of the original paper. Kamei et al. have used  both open source and commercial projects for their study but we replicated it on one single open source project. So, the comparison would be based on the results that we find in the original work for open source projects compared to our results and findings.

\subsection{RQ1-RQ1 Comparison}
\label{sec:comp-rq11}

Research question 1 for both papers wanted to determine how well we can predict defect-inducing changes. The original paper provided the performance prediction metrics for it's 6 open source project and 5 commercial projects. We replicated their process and have obtained the same performance prediction metrics for Django which we can use for the comparison. Given that we did not analyse a commercial project we will disregard those metrics and will perform our comparison on the other open source projects.

\begin{table}
	\centering
	\caption{Comparison of Prediction Performance}
	\begin{tabular}{|p{1cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}||c|c|}
		\hline & \multirow{2}{*}{Acc.} & \multirow{2}{*}{Prec.} & \multirow{2}{*}{Rec.} & \multirow{2}{*}{F1} & \multirow{2}{*}{AUC} & \multicolumn{2}{|c|}{\% improvement} \\ \cline{7-8} 
		 & &  &  &  &  & Prec. & AUC \\  
		\hline Ours & 73.6\% & 70.0\% & 73.6\% & 67.4\% & 69.0\% & 32.6\% & 38.0\% \\ 
		\hline Original OSS Avg. & 71\% & 37\% & 67\% & 45\% & 76\% & 92.6\% & 51.5\% \\ 
		\hline 
	\end{tabular}
	
	\label{table:compare_prediction} 
\end{table}

Table~\ref{table:prediction} represents the prediction result for Django. Our accuracy and precision are better than any of the open source projects that have been used in the original work as illustrated in the comparison table~\ref{table:compare_prediction}. Given that we do see in the other results that we are getting the better performance. Were the linear regression model's performance is compared to the baseline we notice that our results have a lower percentage improvement then that of the original paper. We believe that this would be a result of different baselines. The original paper had few details regarding the model which they used for their random defect-inducing baseline. We attempted to replicate this baseline using the ZeroR, but as the results illustrate this was probably not the one which they were using. 
   

\subsection{RQ2-RQ3 Comparison}
\label{sec:comp-rq23}

Research question 2 from our paper and research question 3 from the original paper wanted to determine what are the major characteristics of defect-inducing changes. At this point Kamei et al. found that "Entropy" is a risk reducing factor. It has the same indication in our research as well. However, "Fix" has an opposite indication in our study. Compared to the original work it is a risk increasing factor while it's a defect reducing factor for us.

Surprisingly the number of sub-systems "NS" is a defect reducing factor in our study while it didn't indicate anything in the original paper. This further contradicts table~\ref{table:factors}. Given that Django is written in a different programming language and is a framework for web applications which different compared to the other open source projects that have been studied by Kamei et al.. This could explain the observed differences. Number of directories "ND" is a poor defect-inducing factor in our study, but it is the largest one which we have observed for Django.

\section{Conclusion}
\label{sec:conclusion}

This paper studies prioritizing quality assurance approach by replicating a similar work done previously to verify the existing approach. Our study results with higher accuracy, precision and recall of 73.6\%, 70.0\% and 73.6\% with F-measure of 67.4\%. We had 33.7\% records that we knew whether they are defect or they are of any other type as we were able to identify only 60\% of the regression data. Our prediction could give us be much better result if we would have higher number of regression data that we know what category they belong to.

Similarly to the original work we could predict the defect-inducing changes using 10 fold data sets. We found some differences for couple of factors in our results while determining the major characteristics of defect-inducing changes. Over all, the change level prediction is an effective approach for prioritizing the actions to take for quality assurance of a software project. This replication work validates that a model which uses logistic regression could be used to provide recommendations for commits which may have a higher probability of being defect-inducing.

\section*{Acknowledgment}
We would like to thank Dr. Bram Adams for providing us with the Django data and for his continued support throughout the completion of this replication paper. We would also give a special thanks to Dr. Peter Rigby who's minimum supervision has allowed us to progress with our work.

\balance
\bibliographystyle{IEEEtran}
\bibliography{assignment.bib}
\end{document}
